{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE475 Project Bonus, Due: Monday, 05/02/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "\n",
    "1. Please submit your Jupyter Notebook file (the. ipynb file) containing your code and the outputs produced by your code (note that .ipynb file can contain both the code and the outputs) to Canvas. Please name your file CSE475-ProjectBonus-LastName-FirstName.ipynb.\n",
    "\n",
    "2. If you have any questions on the homework problems, you should post your question on the Canvas discussion board (under Project Q&A), instead of sending emails to the instructor or TA. We will answer your questions there. In this way, we can avoid repeated questions, and help the entire class stay on the same page whenever any clarification/correction is made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Convolutional Neural Network to classify images in the CIFAR-10 Dataset\n",
    "\n",
    "We will work with the CIFAR-10 Dataset.  This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The 10 classes are:\n",
    "\n",
    "<ol start=\"0\">\n",
    "<li> airplane\n",
    "<li>  automobile\n",
    "<li> bird\n",
    "<li>  cat\n",
    "<li> deer\n",
    "<li> dog\n",
    "<li>  frog\n",
    "<li>  horse\n",
    "<li>  ship\n",
    "<li>  truck\n",
    "</ol>\n",
    "\n",
    "For details about CIFAR-10 see:\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "For a compilation of published performance results on CIFAR 10, see:\n",
    "http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
    "\n",
    "---\n",
    "\n",
    "### Building CNN\n",
    "\n",
    "In this project we will build and train our convolutional neural network. In the first part, we walk through different layers and how they are configured. In the second part, you will build your own model, train it, and compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 23:36:21.993136: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-02 23:36:21.993165: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Each image is a 32 x 32 x 3 numpy array\n",
    "x_train[444].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's look at one of the images\n",
    "\n",
    "print(y_train[444])\n",
    "plt.imshow(x_train[444]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class labels to one-hot vectors\n",
    "num_classes = 10\n",
    "\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see some one-hot vector\n",
    "y_train[444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, let's make everything float and scale\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First CNN\n",
    "Below we will build our first CNN.  For demonstration purpose (so that it will br trained quickly) it is not very deep and has relatively few parameters.  We use strides of 2 in the first two convolutional layers which quickly reduces the dimensions of the output. After a MaxPooling layer, we flatten, and then have a single fully connected layer before the final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "## 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "## Flatten turns 3x3x32 into 288x1\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(512))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 181K parameters, even though this is a \"small\" model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = tensorflow.keras.optimizers.RMSprop(lr=0.0005, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Your task (25pts)\n",
    "\n",
    "Our previous model (model_1) had the structure:\n",
    "\n",
    "Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification (with activation functions and dropouts)\n",
    "\n",
    "Please built a different model (named model_2) by trying different structures and different hyperparameters, such as number of neurons, layers, stride, padding, dropout rate, kernel size, learning rate, number of epochs, etc. You can choose to add data augmentation, batch normalization and/or something new.<br>\n",
    "\n",
    "For example: <br>\n",
    "A deeper model: Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
    "<br>\n",
    "\n",
    "Report the best test accuracy achieved. You will be graded on the highest test accuracy achieved:<br>\n",
    "Test accuracy < Base model (model_1) : 0 - 5pts (Depending on the changes made in model_2)<br>\n",
    "Base model (model_1) < Test accuracy < 70%: 5 - 10pts (Depending on the changes made in model_2)<br>\n",
    "70% < Test accuracy < 75%: 15pts<br>\n",
    "75% < Test accuracy: 25pts <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "model_2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 23:37:32.108781: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 39ms/step - loss: 1.6814 - accuracy: 0.3939 - val_loss: 1.9531 - val_accuracy: 0.3100\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.3342 - accuracy: 0.5231 - val_loss: 1.2667 - val_accuracy: 0.5493\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 1.1937 - accuracy: 0.5757 - val_loss: 1.2002 - val_accuracy: 0.5754\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.0984 - accuracy: 0.6107 - val_loss: 1.2254 - val_accuracy: 0.5782\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.0308 - accuracy: 0.6370 - val_loss: 1.1435 - val_accuracy: 0.6061\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.9690 - accuracy: 0.6575 - val_loss: 1.0606 - val_accuracy: 0.6283\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.9241 - accuracy: 0.6741 - val_loss: 1.0721 - val_accuracy: 0.6283\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.8839 - accuracy: 0.6885 - val_loss: 1.2689 - val_accuracy: 0.5784\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.8417 - accuracy: 0.7029 - val_loss: 1.2207 - val_accuracy: 0.5997\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.8100 - accuracy: 0.7126 - val_loss: 1.1867 - val_accuracy: 0.6180\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.7830 - accuracy: 0.7236 - val_loss: 1.4506 - val_accuracy: 0.5605\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.7544 - accuracy: 0.7338 - val_loss: 1.1337 - val_accuracy: 0.6227\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.7299 - accuracy: 0.7404 - val_loss: 1.0948 - val_accuracy: 0.6359\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.7063 - accuracy: 0.7510 - val_loss: 1.1686 - val_accuracy: 0.6272\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.6881 - accuracy: 0.7548 - val_loss: 1.0832 - val_accuracy: 0.6472\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.6621 - accuracy: 0.7650 - val_loss: 1.1323 - val_accuracy: 0.6379\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.6499 - accuracy: 0.7695 - val_loss: 1.1309 - val_accuracy: 0.6439\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.6307 - accuracy: 0.7757 - val_loss: 1.1485 - val_accuracy: 0.6432\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.6146 - accuracy: 0.7788 - val_loss: 1.1476 - val_accuracy: 0.6461\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.6059 - accuracy: 0.7837 - val_loss: 1.1689 - val_accuracy: 0.6432\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.5850 - accuracy: 0.7904 - val_loss: 1.1735 - val_accuracy: 0.6522\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.5728 - accuracy: 0.7962 - val_loss: 1.2159 - val_accuracy: 0.6404\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.5650 - accuracy: 0.7972 - val_loss: 1.2742 - val_accuracy: 0.6355\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 0.5469 - accuracy: 0.8027 - val_loss: 1.2498 - val_accuracy: 0.6394\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.5308 - accuracy: 0.8112 - val_loss: 1.3685 - val_accuracy: 0.6370\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.5249 - accuracy: 0.8139 - val_loss: 1.2357 - val_accuracy: 0.6490\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.5141 - accuracy: 0.8160 - val_loss: 1.5033 - val_accuracy: 0.6171\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.5061 - accuracy: 0.8188 - val_loss: 1.2649 - val_accuracy: 0.6411\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.4991 - accuracy: 0.8207 - val_loss: 1.3726 - val_accuracy: 0.6355\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.4876 - accuracy: 0.8249 - val_loss: 1.3400 - val_accuracy: 0.6457\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.4800 - accuracy: 0.8272 - val_loss: 1.3863 - val_accuracy: 0.6313\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.4691 - accuracy: 0.8314 - val_loss: 1.3736 - val_accuracy: 0.6435\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.4618 - accuracy: 0.8343 - val_loss: 1.4719 - val_accuracy: 0.6387\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.4534 - accuracy: 0.8378 - val_loss: 1.4156 - val_accuracy: 0.6422\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.4476 - accuracy: 0.8382 - val_loss: 1.4201 - val_accuracy: 0.6393\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.4380 - accuracy: 0.8433 - val_loss: 1.4453 - val_accuracy: 0.6389\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.4327 - accuracy: 0.8450 - val_loss: 1.4526 - val_accuracy: 0.6443\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.4269 - accuracy: 0.8452 - val_loss: 1.4339 - val_accuracy: 0.6516\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.4199 - accuracy: 0.8499 - val_loss: 1.5312 - val_accuracy: 0.6334\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.4194 - accuracy: 0.8488 - val_loss: 1.5044 - val_accuracy: 0.6407\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.4129 - accuracy: 0.8515 - val_loss: 1.6648 - val_accuracy: 0.6249\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.3996 - accuracy: 0.8572 - val_loss: 1.5713 - val_accuracy: 0.6411\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.3958 - accuracy: 0.8586 - val_loss: 1.5822 - val_accuracy: 0.6344\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.3931 - accuracy: 0.8587 - val_loss: 1.5471 - val_accuracy: 0.6452\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.3840 - accuracy: 0.8614 - val_loss: 1.5861 - val_accuracy: 0.6454\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.3808 - accuracy: 0.8637 - val_loss: 1.5585 - val_accuracy: 0.6386\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.3782 - accuracy: 0.8645 - val_loss: 1.5876 - val_accuracy: 0.6394\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.3716 - accuracy: 0.8660 - val_loss: 1.6373 - val_accuracy: 0.6427\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.3671 - accuracy: 0.8701 - val_loss: 1.7112 - val_accuracy: 0.6308\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.3609 - accuracy: 0.8725 - val_loss: 1.6769 - val_accuracy: 0.6368\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.3560 - accuracy: 0.8721 - val_loss: 1.6714 - val_accuracy: 0.6329\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.3479 - accuracy: 0.8741 - val_loss: 1.6952 - val_accuracy: 0.6424\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.3464 - accuracy: 0.8761 - val_loss: 1.7042 - val_accuracy: 0.6329\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.3459 - accuracy: 0.8766 - val_loss: 1.6621 - val_accuracy: 0.6377\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.3435 - accuracy: 0.8777 - val_loss: 1.6902 - val_accuracy: 0.6338\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.3406 - accuracy: 0.8792 - val_loss: 1.8257 - val_accuracy: 0.6424\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 18s 45ms/step - loss: 0.3291 - accuracy: 0.8824 - val_loss: 1.7019 - val_accuracy: 0.6544\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.3267 - accuracy: 0.8834 - val_loss: 1.7198 - val_accuracy: 0.6431\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.3278 - accuracy: 0.8835 - val_loss: 1.8631 - val_accuracy: 0.6359\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.3219 - accuracy: 0.8837 - val_loss: 1.7593 - val_accuracy: 0.6427\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 0.3176 - accuracy: 0.8863 - val_loss: 1.7814 - val_accuracy: 0.6462\n",
      "Epoch 62/100\n",
      "383/391 [============================>.] - ETA: 0s - loss: 0.3126 - accuracy: 0.8889"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Let's train the model using RMSprop\u001b[39;00m\n\u001b[1;32m     35\u001b[0m model_2\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mopt,\n\u001b[1;32m     37\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 39\u001b[0m \u001b[43mmodel_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m              \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model_2.add(Conv2D(32, (3, 3), strides = (2,2),activation=\"relu\", padding='same', input_shape=x_train.shape[1:]))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(32, (3, 3), strides = (2,2), activation=\"relu\", padding=\"same\"))\n",
    "model_2.add(MaxPooling2D((2, 2),padding = \"same\"))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "model_2.add(Conv2D(64, (3, 3), strides = (2,2),activation=\"relu\", padding='same', input_shape=x_train.shape[1:]))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(64, (3, 3), strides = (2,2), activation=\"relu\", padding=\"same\"))\n",
    "model_2.add(MaxPooling2D((2, 2),padding = \"same\"))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "model_2.add(Conv2D(128, (3, 3), strides = (2,2),activation=\"relu\", padding='same', input_shape=x_train.shape[1:]))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(128, (3, 3), strides = (2,2), activation=\"relu\", padding=\"same\"))\n",
    "model_2.add(MaxPooling2D((2, 2),padding = \"same\"))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dropout(0.3))\n",
    "model_2.add(Dense(512, activation=\"relu\"))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dropout(0.3))\n",
    "\n",
    "model_2.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = tensorflow.keras.optimizers.RMSprop(lr=0.0005, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.8181278705596924\n",
      "Test accuracy: 0.6388999819755554\n"
     ]
    }
   ],
   "source": [
    "# Test the model on test data\n",
    "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
